{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi1lnyToWe-E",
        "outputId": "85f2283d-c4ad-4858-a37f-90f2f1e3f3e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Execution Time: 48.39 seconds\n",
            "+-----------------------------------+----------+---------+\n",
            "|tweet                              |prediction|sentiment|\n",
            "+-----------------------------------+----------+---------+\n",
            "|i hate this product its the worst  |1.0       |Negative |\n",
            "|this is amazing i love it          |0.0       |Positive |\n",
            "|not bad but could be better        |0.0       |Positive |\n",
            "|absolutely terrible experience     |1.0       |Negative |\n",
            "|had a fantastic time using this app|0.0       |Positive |\n",
            "+-----------------------------------+----------+---------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lower, regexp_replace, when, rand\n",
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, IDF\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"FixedSentimentAnalysis\").getOrCreate()\n",
        "start_time = time.time()\n",
        "\n",
        "# Load dataset\n",
        "df = spark.read.csv(\"twitter.csv\", header=True, inferSchema=True).select(\"tweet\", \"label\")\n",
        "\n",
        "# Clean tweets\n",
        "df_clean = df.withColumn(\"tweet\", lower(col(\"tweet\")))\n",
        "df_clean = df_clean.withColumn(\"tweet\", regexp_replace(\"tweet\", r\"http\\S+|www\\S+\", \"\"))\n",
        "df_clean = df_clean.withColumn(\"tweet\", regexp_replace(\"tweet\", r\"@\\w+\", \"\"))\n",
        "df_clean = df_clean.withColumn(\"tweet\", regexp_replace(\"tweet\", r\"#\", \"\"))\n",
        "df_clean = df_clean.withColumn(\"tweet\", regexp_replace(\"tweet\", r\"[^\\w\\s]\", \"\"))\n",
        "df_clean = df_clean.withColumn(\"tweet\", regexp_replace(\"tweet\", r\"\\d+\", \"\"))\n",
        "\n",
        "# Handle class imbalance\n",
        "positive = df_clean.filter(col(\"label\") == 1)\n",
        "negative = df_clean.filter(col(\"label\") == 0)\n",
        "neg_sample = negative.sample(False, positive.count() / negative.count(), seed=42)\n",
        "df_train = neg_sample.union(positive).orderBy(rand())\n",
        "\n",
        "# Test sentences\n",
        "test_sentences = [\n",
        "    (\"I hate this product! It's the worst!\",),\n",
        "    (\"This is amazing! I love it.\",),\n",
        "    (\"Not bad, but could be better.\",),\n",
        "    (\"Absolutely terrible experience.\",),\n",
        "    (\"Had a fantastic time using this app.\",),\n",
        "]\n",
        "df_test = spark.createDataFrame(test_sentences, [\"tweet\"])\n",
        "\n",
        "# Clean test tweets\n",
        "for pattern in [r\"http\\S+|www\\S+\", r\"@\\w+\", r\"#\", r\"[^\\w\\s]\", r\"\\d+\"]:\n",
        "    df_test = df_test.withColumn(\"tweet\", regexp_replace(\"tweet\", pattern, \"\"))\n",
        "df_test = df_test.withColumn(\"tweet\", lower(col(\"tweet\")))\n",
        "\n",
        "# ML Pipeline\n",
        "tokenizer = RegexTokenizer(inputCol=\"tweet\", outputCol=\"words\", pattern=\"\\\\W\")\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
        "vectorizer = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"raw_features\", vocabSize=10000)\n",
        "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")  # <-- use original label\n",
        "\n",
        "pipeline = Pipeline(stages=[tokenizer, remover, vectorizer, idf, lr])\n",
        "\n",
        "# Train model\n",
        "model = pipeline.fit(df_train)\n",
        "\n",
        "# Predict\n",
        "predictions = model.transform(df_test)\n",
        "\n",
        "# Map prediction\n",
        "predictions = predictions.withColumn(\n",
        "    \"sentiment\",\n",
        "    when(col(\"prediction\") == 1.0, \"Negative\").otherwise(\"Positive\")\n",
        ")\n",
        "\n",
        "print(f\"\\nExecution Time: {time.time() - start_time:.2f} seconds\")\n",
        "predictions.select(\"tweet\", \"prediction\", \"sentiment\").show(truncate=False)\n",
        "\n",
        "# Stop Spark\n",
        "spark.stop()\n"
      ]
    }
  ]
}